{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d0657f-d4b3-49bb-b884-5a25929c4611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "print(torch.cuda.device_count())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # For multi-GPU setups, if any\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Example usage\n",
    "set_seed(42)  # Replace 42 with your chosen seed\n",
    "\n",
    "phase = 1\n",
    "#https://ieeexplore.ieee.org/document/10245477"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21d8874-c701-453e-a046-322de8122549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1a53e5-a631-41e5-9c08-de6fa0c8e17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalizaData(df):\n",
    "    # Convert DataFrame to PyTorch Tensor and send to GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Normalizing Angular Data (Robotic Joints)\n",
    "    rad_cols = ['Tool_rx', 'Tool_ry', 'Tool_rz', 'Joint_base', 'Joint_Shoulder', 'Joint_Elbow', 'Joint_W1', 'Joint_W2', 'Joint_W3']\n",
    "    for col in rad_cols:\n",
    "        # Ensure the data is in the form of a PyTorch Tensor\n",
    "        rad_tensor = torch.tensor(df[col].values, device=device, dtype=torch.float32)\n",
    "        df[col + '_cos'] = torch.cos(rad_tensor).cpu().numpy()  # Compute cosine and convert back to NumPy for DataFrame\n",
    "        df[col + '_sin'] = torch.sin(rad_tensor).cpu().numpy()  # Compute sine and convert back to NumPy for DataFrame\n",
    "    \n",
    "    # Normalizing Linear Data (Speed, Acceleration, Energy Consumed, and Time)\n",
    "    # Min-Max Scaling: Scales the data to a fixed range, typically 0 to 1\n",
    "    scaler = MinMaxScaler()\n",
    "    linear_cols = ['Speed', 'Acceleration', 'Time', 'Energy_Consumped']\n",
    "    df[linear_cols] = scaler.fit_transform(df[linear_cols])\n",
    "    \n",
    "    return df, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655081f-d02c-4c6a-9c87-3c6f86996916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_data(arr, scaler, features):\n",
    "    \n",
    "    \"\"\"\n",
    "    Denormalizes the data from a normalized array using the provided scaler.\n",
    "    \n",
    "    Parameters:\n",
    "    - arr (numpy.ndarray): The normalized array to be denormalized. Expected shape: (samples, features, timesteps).\n",
    "    - scaler (MinMaxScaler or StandardScaler): The scaler used to normalize the data.\n",
    "    - features (list): List of feature names for the DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with denormalized data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Reshape array into 2D (flatten the timesteps) and create DataFrame\n",
    "    reshaped_array = arr.reshape(-1, arr.shape[2])\n",
    "    df = pd.DataFrame(reshaped_array, columns=features)\n",
    "    \n",
    "    # Denormalizing Angular Data\n",
    "    # Identify columns related to cosine and sine representations\n",
    "    angle_columns = [col for col in df.columns if '_cos' in col or '_sin' in col]\n",
    "    \n",
    "    # Set to keep track of processed base columns to avoid duplicates\n",
    "    processed_bases = set()\n",
    "    \n",
    "    for col in angle_columns:\n",
    "        if '_cos' in col:\n",
    "            base_col = col.replace('_cos', '')\n",
    "            if base_col not in processed_bases:\n",
    "                # Combine cosine and sine to compute the angle\n",
    "                df[base_col] = np.arctan2(df[base_col + '_sin'], df[base_col + '_cos'])\n",
    "                # Remove the original cosine and sine columns\n",
    "                df.drop(columns=[base_col + '_sin', base_col + '_cos'], inplace=True)\n",
    "                # Mark the base column as processed\n",
    "                processed_bases.add(base_col)\n",
    "    \n",
    "    # Denormalizing Linear Data\n",
    "    # List of columns to denormalize\n",
    "    linear_columns = ['Speed', 'Acceleration', 'Time', 'Energy_Consumped']\n",
    "    \n",
    "    # Ensure all specified columns are in the DataFrame before attempting denormalization\n",
    "    available_linear_columns = [col for col in linear_columns if col in df.columns]\n",
    "    \n",
    "    if available_linear_columns:\n",
    "        df[available_linear_columns] = scaler.inverse_transform(df[available_linear_columns])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2e3597-c64b-4ab1-b984-676be2f95143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Load data\n",
    "real_data = pd.read_csv('phase RLHF dataset/remaining_paths.csv')\n",
    "\n",
    "\n",
    "# Fix a typo in the 'point_type' column\n",
    "real_data['point_type'] = real_data['point_type'].replace('approuch', 'approach')\n",
    "\n",
    "# Map 'point_type' and 'Movement Type' to numeric values\n",
    "points = {'pick': 1, 'approach': 2, 'start_point': 3, 'box1': 4, 'way_point': 5}\n",
    "movement_types = {'MoveL': 1, 'MoveJ': 2, 'Movel': 1, 'Movej': 2}\n",
    "real_data['point_type'] = real_data['point_type'].map(points)\n",
    "real_data['Movement Type'] = real_data['Movement Type'].map(movement_types)\n",
    "\n",
    "# Drop columns 'id' and 'row_index'\n",
    "real_data.drop(['id'], axis=1, inplace=True)\n",
    "\n",
    "# Assuming here that the use of PyTorch would be to handle numeric data for neural network processing\n",
    "# Convert DataFrame to PyTorch Tensor and send to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tensor_data = torch.tensor(real_data.values, dtype=torch.float, device=device)\n",
    "\n",
    "# Print number of columns in the DataFrame\n",
    "print(len(real_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213b8a4f-73af-42c1-a364-341fc5746c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "df_normalized, scaler = normalizaData(real_data.copy())\n",
    "\n",
    "# Define the features to be used\n",
    "features = [\n",
    "    'point_type', 'Tool_x', 'Tool_y', 'Tool_z', 'Tool_rx_cos', 'Tool_rx_sin', 'Tool_ry_cos',\n",
    "    'Tool_ry_sin', 'Tool_rz_cos', 'Tool_rz_sin', 'Joint_base_cos',\n",
    "    'Joint_base_sin', 'Joint_Shoulder_cos', 'Joint_Shoulder_sin',\n",
    "    'Joint_Elbow_cos', 'Joint_Elbow_sin', 'Joint_W1_cos', 'Joint_W1_sin',\n",
    "    'Joint_W2_cos', 'Joint_W2_sin', 'Joint_W3_cos', 'Joint_W3_sin', 'Speed', 'Acceleration', 'Movement Type', 'Time', 'Energy_Consumped'\n",
    "]\n",
    "\n",
    "# Calculate the number of features\n",
    "features_num = len(features)\n",
    "\n",
    "# Select the specified features from the normalized DataFrame\n",
    "df_normalized = df_normalized[features]\n",
    "\n",
    "# Display the first few rows of the selected features\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754b504b-c57f-49a7-ab91-10e2231fe301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df_normalized has been defined and features_num has been calculated as before\n",
    "# Add a 'path_id' column to help in grouping. Creating a dummy 'path_id' that repeats every 5 rows\n",
    "num_paths = len(df_normalized) // 5  # Use integer division\n",
    "path_id = np.repeat(np.arange(num_paths), 5)\n",
    "df_normalized['path_id'] = path_id\n",
    "\n",
    "# Ensure the length of path_id matches the number of rows in df_normalized\n",
    "if len(path_id) < len(df_normalized):\n",
    "    extra_ids = np.array([num_paths] * (len(df_normalized) - len(path_id)))\n",
    "    path_id = np.concatenate([path_id, extra_ids])\n",
    "\n",
    "# Now, sort and group by 'path_id' and reshape\n",
    "grouped = df_normalized.groupby('path_id').apply(lambda x: x.iloc[:, :-1].values.reshape(1, 5, features_num))\n",
    "\n",
    "# Drop the 'path_id' column after reshaping\n",
    "df_normalized.drop(['path_id'], axis=1, inplace=True)\n",
    "\n",
    "# Concatenate the groups back into a single numpy array\n",
    "reshaped_data = np.concatenate(grouped.values, axis=0)\n",
    "print(reshaped_data.shape)\n",
    "# Save the reshaped data to a file. Assume 'phase' is defined elsewhere\n",
    "np.save(f\"TGANreal_normalized_dataset_shape_3D_ph{phase}.npy\", reshaped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b98c2e-d64e-4ac2-bd39-a070168d0fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.parametrizations import weight_norm\n",
    "\n",
    "#The Chomp1d module in the context of Temporal Convolutional Networks (TCNs) is a custom PyTorch module designed to manage\n",
    "#the issue of padding in convolutional layers that are used for time series data. \n",
    "#In convolutional operations, padding is often added to ensure that the convolution output has the same length as the input, \n",
    "#which is particularly important for building deep networks that do not reduce the temporal dimension until desired.\n",
    "\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.tcn = TemporalConvNet(num_inputs=27, num_channels=[50, 50, 27], kernel_size=2, dropout=0.3)\n",
    "        self.linear = nn.Linear(27*5, 27*5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)  # Convert to (batch, channels, length)\n",
    "        x = self.tcn(x)\n",
    "        x = x.transpose(1, 2)  # Convert back to (batch, length, channels)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        return x.reshape(x.size(0), 5, 27)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(27, 50, 3, 1, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv1d(50, 50, 3, 1, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv1d(50, 1, 3, 1, 1),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)  # Convert to (batch, channels, length)\n",
    "        x = self.cnn(x)\n",
    "        return x\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Instantiate the models and move them to the device\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feecec2f-6d07-4719-872c-ecdc9b539397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def generate_noise(batch_size, noise_dim, seed=None):\n",
    "\n",
    "    return  torch.randn(batch_size, 5, 27, device=device) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208df75e-0e8c-4760-a858-63e6c7a053e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def physics_loss(fake_data):\n",
    "    \"\"\"\n",
    "    Calculate the physics-based loss for generated data.\n",
    "\n",
    "    Parameters:\n",
    "    - fake_data (torch.Tensor): Generated data with shape (batch_size, seq_len, num_features).\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: Total physics loss.\n",
    "    \"\"\"\n",
    "    fake_data_numpy = fake_data.detach().cpu().numpy()\n",
    "\n",
    "    df = denormalize_data(fake_data_numpy , scaler, features)\n",
    "    '''Index(['point_type', 'Tool_x', 'Tool_y', 'Tool_z', 'Speed', 'Acceleration',\n",
    "       'Movement Type', 'Time', 'Energy_Consumped', 'Tool_rx', 'Tool_ry',\n",
    "       'Tool_rz', 'Joint_base', 'Joint_Shoulder', 'Joint_Elbow', 'Joint_W1',\n",
    "       'Joint_W2', 'Joint_W3'],\n",
    "      dtype='object') '''\n",
    "    #Penalty for negative values in specific columns\n",
    "\n",
    "    #Movement type 1-> moveL , 2-> moveJ \n",
    "    #Tool x,y,z # Move l ,speed 0-3000 mm/s -> 0-3 m/s\n",
    "    #Tool x,y,z # Move l ,acceleration 0-150000 mm/s2 - 0-150 m/s \n",
    "    #Denormalize speed , 13 index in real data , 22 speed in normalized data\n",
    "    #[-25.2721, -25.7903, -25.5148, -25.1693, -24.9287],\n",
    "\n",
    "    # Speed constraints for MoveL\n",
    "    # i assume movment type = 1 if less than 0.5 \n",
    "    filtered_speed = len(df[(df['Speed'] >= 0) & (df['Speed'] <= 3) & (df['Movement Type'] <= 1)])\n",
    "    filtered_Acceleration = len(df[(df['Acceleration'] >= 0) & (df['Acceleration'] <= 150) & (df['Movement Type'] <= 1)])\n",
    "    speed_loss_l = filtered_speed\n",
    "    acc_loss_l = filtered_Acceleration\n",
    "  \n",
    "\n",
    "    # Speed constraints for MoveJ\n",
    "        #rx,ry,rz,joints \n",
    "        #Move J speed 0-180 degree per second -> radian 3.14159\n",
    "        #Move J acceleration 0 - 2292  degree/second ^2 -> radian 40\n",
    "    filtered_speed_mj = len(df[(df['Speed'] >= 0) & (df['Speed'] <=  3.14159) & (df['Movement Type'] >=1)])\n",
    "    filtered_Acceleration_mj = len(df[(df['Acceleration'] >= 0) & (df['Acceleration'] <= 40) & (df['Movement Type'] >= 1)])\n",
    "    speed_loss_j = filtered_speed_mj\n",
    "    acc_loss_j = filtered_Acceleration_mj\n",
    "  \n",
    "\n",
    "    # Joint angle constraints\n",
    "       #validate_joint_angles\n",
    "        #-363 to 363 degree/s ---->    -6.33555 , 6.33555 rad\n",
    "        #Joint limits as defined in the screenshot\n",
    "    joint_columns = ['Joint_base', 'Joint_Shoulder', 'Joint_Elbow', 'Joint_W1', 'Joint_W2', 'Joint_W3']\n",
    "    # Filter the DataFrame\n",
    "    filtered_df_joints = df[(df[joint_columns] < -6.33555) | (df[joint_columns] > 6.33555)].dropna(how='all', subset=joint_columns)\n",
    "    joints_loss = len(filtered_df_joints)\n",
    "   \n",
    "    #time, energy negative \n",
    "    filtered_df = df[(df['Time'] < 0) | (df['Energy_Consumped'] < 0)]\n",
    "    time_energy_loss = len(filtered_df)\n",
    "    total_loss = speed_loss_l + acc_loss_l + speed_loss_j + acc_loss_j + joints_loss + time_energy_loss\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f61c7-5bc2-410a-8526-fb285f02d3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'data' is your dataset available as a NumPy array\n",
    "# data shape should be (num_samples, time_steps, features) = (any, 5, 27)\n",
    "   \n",
    "# Training loop\n",
    "num_epochs = 5000  # You can adjust the number of epochs\n",
    "noise_dim = 1000\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "def train(param_grid):\n",
    "    tensor_data = torch.tensor(reshaped_data, dtype=torch.float32)\n",
    "    dataset = TensorDataset(tensor_data)\n",
    "    data_loader = DataLoader(dataset, batch_size=33, shuffle=True)\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    # Optimizers\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    " \n",
    "    losses = [] \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for real_data_tensor, in data_loader:\n",
    "            real_data_tensor = real_data_tensor.to(device)\n",
    "            \n",
    "            # Train Discriminator\n",
    "            # Generate fake data\n",
    "            noise = generate_noise(len(real_data), noise_dim)\n",
    "           # Random noise\n",
    "            fake_data = generator(noise)\n",
    "    \n",
    "            # Get discriminator results for real and fake data\n",
    "            D_real = discriminator(real_data_tensor).view(-1)\n",
    "            D_fake = discriminator(fake_data.detach()).view(-1)\n",
    "    \n",
    "            # Calculate loss on real and fake data\n",
    "            loss_D_real = criterion(D_real, torch.ones_like(D_real))\n",
    "            loss_D_fake = criterion(D_fake, torch.zeros_like(D_fake))\n",
    "            loss_D = (loss_D_real + loss_D_fake) / 2\n",
    "    \n",
    "            # Update discriminator\n",
    "            optimizer_D.zero_grad()\n",
    "            loss_D.backward()\n",
    "            optimizer_D.step()\n",
    "    \n",
    "            # Train Generator\n",
    "            # Get discriminator results for fake data\n",
    "            output = discriminator(fake_data).view(-1)\n",
    "            \n",
    "            # Calculate loss for generator \n",
    "            phy_factor = param_grid\n",
    "            loss_G = criterion(output, torch.ones_like(output)) + phy_factor * physics_loss(fake_data)\n",
    "    \n",
    "            # Update generator\n",
    "            optimizer_G.zero_grad()\n",
    "            loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "    \n",
    "        # Optionally print the training progress\n",
    "        losses.append({\"epoch\": epoch, \"D Loss\": loss_D.item(), \"G Loss\": loss_G.item()})\n",
    "        if (epoch+1) % 50 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}] Loss discriminator: {loss_D.item():.4f}, Loss generator: {loss_G.item():.4f}\")\n",
    "    d_losses = [loss['D Loss'] for loss in losses]  # Assuming this contains total D loss\n",
    "    g_losses = [loss['G Loss'] for loss in losses]  # Assuming this contains G loss\n",
    "    return generator, discriminator, np.mean(g_losses), losses\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e183bcd1-2cbd-4bfb-b4b0-6d9fb9416de3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2d6275-e3cf-4fb5-bc6f-acb299c2910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Grid search\n",
    "best_loss = float('inf')\n",
    "best_params = {}\n",
    "phy_factor_param = [0.2] #[0.2, 0.5, 1, 2 ] \n",
    "for value in phy_factor_param:\n",
    "    print(value)\n",
    "    generator, discriminator, gloss, losses = train(value)\n",
    "    if gloss < best_loss:\n",
    "        best_loss = gloss\n",
    "        best_params = {\"phy_factor_param\":value, \"generator_model\": generator, \"discriminator_model\": discriminator, \"gloss\": gloss, \"losses\":losses}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ddd726-6872-4ebb-b043-80496d96258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params['phy_factor_param'], best_params['gloss'] #mean for g loss\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06647a71-cb9a-419f-9b49-26f12cbffcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models if needed\n",
    "generator = best_params['generator_model']\n",
    "discriminator = best_params['discriminator_model']\n",
    "losses = best_params['losses']\n",
    "torch.save(generator.state_dict(), 'generatorTGAN.pth')\n",
    "torch.save(discriminator.state_dict(), 'discriminatorTGAN.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad1edf6-de5b-4395-a6a8-4a08839627e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot \n",
    "\n",
    "# Generate fake data\n",
    "noise = generate_noise(len(real_data), noise_dim)\n",
    "# Random noise\n",
    "fake_data = generator(noise)\n",
    "\n",
    "dot = make_dot(generator(noise), params=dict(generator.named_parameters()))\n",
    "dot.render('generator_graph_TGAN', format='png')  # Saves the graph as a PNG file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbb84d4-d4f6-4d3c-866f-f51e1c617fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming `losses` is a list of dictionaries containing 'epoch', 'D Loss', and 'G Loss'\n",
    "# Extracting the data\n",
    "epochs_ls = [i for i in range(1, num_epochs + 1)]  # Integer epochs\n",
    "d_losses = [loss['D Loss'] for loss in losses]  # Assuming this contains total D loss\n",
    "g_losses = [loss['G Loss'] for loss in losses]  # Assuming this contains G loss\n",
    "print(np.mean(d_losses))\n",
    "print(np.mean(g_losses))\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs_ls, d_losses, label='Discriminator Loss')\n",
    "plt.plot(epochs_ls, g_losses, label='Generator Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Losses Over Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('Training_Losses_Over_EpochsTCN.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e72c25-9723-4951-8d81-acb074b40c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(generator, sample_count, noise_dim,seed=None):\n",
    "    \"\"\"\n",
    "    Generate samples using the generator.\n",
    "\n",
    "    Parameters:\n",
    "    - generator (nn.Module): The generator model.\n",
    "    - sample_count (int): Total number of samples to generate.\n",
    "    - noise_dim (int): Dimension of the noise vector.\n",
    "    - seed (int, optional): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: Generated samples tensor.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    batch_size = len(reshaped_data)\n",
    "    all_samples = []\n",
    "\n",
    "    # Calculate number of full batches\n",
    "    num_full_batches = sample_count // batch_size\n",
    "\n",
    "    for i in range(num_full_batches):\n",
    "        # Generate noise for the batch\n",
    "        noise = generate_noise(batch_size, noise_dim).to(device)\n",
    "        \n",
    "        with torch.no_grad():  # Disable gradient calculation for inference\n",
    "            samples = generator(noise).cpu()  # Move samples to CPU for concatenation\n",
    "        all_samples.append(samples)\n",
    "\n",
    "    # Handle the remainder if sample_count isn't a perfect multiple of batch_size\n",
    "    remainder = sample_count % batch_size\n",
    "    if remainder > 0:\n",
    "        noise = generate_noise(remainder, noise_dim, seed=seed).to(device)\n",
    "        with torch.no_grad():  # Disable gradient calculation for inference\n",
    "            samples = generator(noise).cpu()  # Move samples to CPU for concatenation\n",
    "\n",
    "        all_samples.append(samples)\n",
    "\n",
    "    # Concatenate all samples into a single tensor\n",
    "    return torch.cat(all_samples, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eae67d-0cef-4c9e-8e9c-bf94b78e9eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples\n",
    "noise_dim = 1000  # This should match the dimension used during training\n",
    "sample_count = 1000\n",
    "\n",
    "# Generate samples using a for loop\n",
    "generated_samples = []\n",
    "for i in range(sample_count):\n",
    "    sample = generate_samples(generator, 1, noise_dim)\n",
    "    generated_samples.append(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59591de3-69be-4d18-9445-7f363e48cea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the generated samples\n",
    "concatenated_tensor = torch.cat(generated_samples, dim=0)\n",
    "\n",
    "# Convert to NumPy array (if you need to save it as a .npy file)\n",
    "concatenated_array = concatenated_tensor.cpu().numpy()\n",
    "4# Save to file\n",
    "np.save(\"syntheticData_100Samplewgan.npy\", concatenated_array)\n",
    "concatenated_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990e7e95-4747-4a95-b6b2-d4e84544b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Selecting the last column from each series\n",
    "energy_col = concatenated_array[:, :, -1]\n",
    "energy_sums = np.sum(energy_col, axis=1)\n",
    "time_col = concatenated_array[:, :, -2]\n",
    "\n",
    "# Summing across the rows (time steps)\n",
    "time_sums = np.sum(time_col, axis=1)\n",
    "\n",
    "plt.scatter(time_sums, energy_sums, alpha=0.6)\n",
    "plt.title('Synthetic Paths - Distribution of Cycle Time and Energy')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Energy')\n",
    "plt.savefig('Synthetic Data - Distribution of Cycle Time and Energywgan.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971c7a41-fbf8-4431-ab24-5174e5a91f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract normalized time and energy into separate variables\n",
    "denormalize_generated_data = denormalize_data(concatenated_array, scaler, features)\n",
    "print()\n",
    "denormalize_generated_data.to_csv(\"denormalized_sythData_phase1_waed_wgan.csv\")\n",
    "\n",
    "time_denorm = denormalize_generated_data['Time']  # Assuming time is the second last column\n",
    "energy_denorm = denormalize_generated_data['Energy_Consumped']  # Assuming energy is the last column\n",
    "\n",
    "# Ensure the series length is a multiple of 5\n",
    "n = 5\n",
    "length = len(time_denorm)\n",
    "trimmed_length = length - (length % n)\n",
    "# Trim the series if necessary\n",
    "trimmed_series = time_denorm[:trimmed_length]\n",
    "# Reshape to groups of 5\n",
    "reshaped_array = trimmed_series.to_numpy().reshape(-1, n)\n",
    "# Sum each group of 5\n",
    "time_denorm_sums = reshaped_array.sum(axis=1)\n",
    "trimmed_series = energy_denorm[:trimmed_length]\n",
    "# Reshape to groups of 5\n",
    "reshaped_array = energy_denorm.to_numpy().reshape(-1, n)\n",
    "# Sum each group of 5\n",
    "energy_denorm_sums = reshaped_array.sum(axis=1)\n",
    "\n",
    "# Plotting\n",
    "plt.scatter(time_denorm_sums, energy_denorm_sums, color='blue')\n",
    "\n",
    "# Set title and labels\n",
    "plt.title('Synthetic Paths - Distribution of Cycle Time and Energy')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Energy')\n",
    "\n",
    "# Save and show the plot\n",
    "plt.savefig('denormalize-Synthetic Datawgan.pdf')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafb9059-bb5a-4139-a8b8-02938a0f89b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "denormalize_generated_data.to_csv(\"denormalize_generated_data_tgan_adam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1ac838-2daa-41af-85b0-1573b72f2914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "last_col = real_data.iloc[:, 17]\n",
    "# Group by each set of five rows and sum\n",
    "# np.arange(len(last_col)) // 5 creates an integer index for each group of five\n",
    "energy_real = last_col.groupby(np.arange(len(last_col)) // 5).sum()\n",
    "last_col = real_data.iloc[:, 16]\n",
    "time_real = last_col.groupby(np.arange(len(last_col)) // 5).sum()\n",
    "\n",
    "plt.scatter(time_denorm_sums, energy_denorm_sums, color='blue',label='Synthetic Psths')\n",
    "plt.scatter(time_real, energy_real, color='green',label='Real Paths')\n",
    "\n",
    "plt.title('Synthetic & Real Paths- Distribution of Cycle time and Energy')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Energy')\n",
    "plt.legend()\n",
    "plt.savefig('Synthetic & Real Paths- Distribution of Cycle time and Energy tgan.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bb04a4-f428-4215-ae7e-4987cd37fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_16 = time_denorm_sums.flatten()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(col_16, kde=True, bins=10 , label = \"Time\")\n",
    "plt.title('Synthetic Data - Distribution of Cycle time')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.savefig(\"denormalized_data- Sythetic Data - Distribution of Cycle time tgan.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f11b030-cd95-446e-82b8-65a343a5038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate random data points for Time and Energy\n",
    "np.random.seed(0)  # For reproducibility\n",
    "time = time_denorm_sums\n",
    "energy = energy_denorm_sums\n",
    "\n",
    "# Function to identify Pareto optimal points\n",
    "def identify_pareto(scores):\n",
    "    # Initialize a boolean array to identify Pareto points\n",
    "    is_pareto = np.ones(scores.shape[0], dtype=bool)\n",
    "    for i in range(scores.shape[0]):\n",
    "        for j in range(scores.shape[0]):\n",
    "            if all(scores[j] <= scores[i]) and any(scores[j] < scores[i]):\n",
    "                is_pareto[i] = False\n",
    "                break\n",
    "    return is_pareto\n",
    "\n",
    "# Identify Pareto front\n",
    "pareto_points = identify_pareto(np.c_[time, energy])\n",
    "pareto_time = time[pareto_points]\n",
    "pareto_energy = energy[pareto_points]\n",
    "\n",
    "# Ensure there are Pareto points before proceeding\n",
    "\n",
    "if pareto_time.size > 0 and pareto_energy.size > 0:\n",
    "    # Select the best point based on the shortest Euclidean distance from the origin\n",
    "    distances = np.sqrt(pareto_time**2 + pareto_energy**2)\n",
    "    best_index = np.argmin(distances)\n",
    "    best_time = pareto_time[best_index]\n",
    "    best_energy = pareto_energy[best_index]\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(time, energy, color='gray', label='Sythetic Paths')\n",
    "    plt.scatter(time_real, energy_real, color='green', label='Real Paths')\n",
    "\n",
    "    plt.scatter(pareto_time, pareto_energy, color='blue', label='Pareto Front')\n",
    "    plt.scatter(best_time, best_energy, color='red', label='Best Point')\n",
    "    plt.plot([0, best_time], [best_energy, best_energy], 'k--', lw=1)  # Horizontal line to Best Point\n",
    "    plt.plot([best_time, best_time], [0, best_energy], 'k--', lw=1)  # Vertical line to Best Point\n",
    "    plt.text(best_time, best_energy, ' Best Point', verticalalignment='bottom')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Energy')\n",
    "    plt.title('Pareto Front with Best Selected Point')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"pareto_front_bsp_tgan_2.pdf\")\n",
    "    #plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"No Pareto optimal points were identified.\")\n",
    "print(best_time,best_energy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf23c24-30de-4822-9b4d-aab2cd2a16f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "# Improvement calculation\n",
    "def improvement_ratio(real, generated):\n",
    "    time_improvement = (real[0] - generated[0]) / real[0] if real[0] != 0 else 0\n",
    "    energy_improvement = (real[1] - generated[1]) / real[1] if real[1] != 0 else 0\n",
    "    return time_improvement, energy_improvement\n",
    "\n",
    "# Example usage:\n",
    "real_point = (3.18, 58.5091)\n",
    "generated_point = (best_time, best_energy)\n",
    "\n",
    "\n",
    "# Get improvements\n",
    "time_improvement, energy_improvement = improvement_ratio(real_point, generated_point)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Time Improvement Ratio: {time_improvement:.2%}\")\n",
    "print(f\"Energy Improvement Ratio: {energy_improvement:.2%}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a47b0b4-377c-4d95-83e2-7702634967da",
   "metadata": {},
   "source": [
    "# Phase 2  , Take the fav/accurate points from the engineer then re-fine-tune the generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916eb6bd-8b80-42e2-8e90-febc4b29da7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model weights\n",
    "generator.load_state_dict(torch.load('generatorTGAN.pth'))\n",
    "discriminator.load_state_dict(torch.load('discriminatorTGAN.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fe7e7b-3e98-4bca-bf8d-7e1be2e33d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collect_human_feedback(samples):\n",
    "    # Ensure samples are on GPU\n",
    "    samples = samples.to(device)\n",
    "    alpha = 0.5\n",
    "    feedback =[]\n",
    "    for sample in samples:\n",
    "        #lower values are better\n",
    "        rating = (sample[:,-2].sum() * alpha + sample[:,-1].sum() *(1-alpha))\n",
    "        feedback.append(float(rating))\n",
    "    \n",
    "    return torch.tensor(feedback, dtype=torch.float).to(device)\n",
    "#feedback -> i want to be small value , mse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdcc03b-bda3-4056-bbaf-488f589ac4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Assuming `generator_ph1` is your policy network and already defined\n",
    "policy_network = generator\n",
    "\n",
    "# Define the value network in PyTorch\n",
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self, input_features):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense1 = nn.Linear(input_features, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(128, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    "\n",
    "# Assume 'features' is defined elsewhere and provides the number of input features\n",
    "input_dim = 5 * len(features)  # Update with the actual size of 'features'\n",
    "value_network = ValueNetwork(input_dim).to(device)\n",
    "\n",
    "optimizer_value = optim.Adam(value_network.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b52c4bc-2d92-406e-84db-dece6b48fdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'data' is your dataset available as a NumPy array\n",
    "# data shape should be (num_samples, time_steps, features) = (any, 5, 27)\n",
    "\n",
    "hfrl_paths = pd.read_csv(\"phase RLHF dataset/least_energy_time_paths.csv\")\n",
    "\n",
    "# Fix a typo in the 'point_type' column\n",
    "real_data['point_type'] = hfrl_paths['point_type'].replace('approuch', 'approach')\n",
    "\n",
    "# Map 'point_type' and 'Movement Type' to numeric values\n",
    "points = {'pick': 1, 'approach': 2, 'start_point': 3, 'box1': 4, 'way_point': 5}\n",
    "movement_types = {'MoveL': 1, 'MoveJ': 2, 'Movel': 1, 'Movej': 2}\n",
    "hfrl_paths['point_type'] = hfrl_paths['point_type'].map(points)\n",
    "hfrl_paths['Movement Type'] = hfrl_paths['Movement Type'].map(movement_types)\n",
    "\n",
    "# Drop columns 'id' and 'row_index'\n",
    "hfrl_paths.drop(['id'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "hfrl_paths_normalized, scaler_ph2 = normalizaData(hfrl_paths)\n",
    "\n",
    "#exclude the  Joint_W3 and keep sin , cos\n",
    "hfrl_paths_normalized= hfrl_paths_normalized[features]\n",
    "num_paths = len(hfrl_paths) // 5\n",
    "batch_size = num_paths #all data \n",
    "\n",
    "path_id = np.repeat(np.arange(num_paths), 5)\n",
    "hfrl_paths_normalized['path_id'] = path_id\n",
    "grouped = hfrl_paths_normalized.groupby('path_id').apply(lambda x: x.values[:, :-1].reshape(1, 5,features_num))\n",
    "hfrl_paths_normalized.drop(['path_id'], axis=1, inplace=True)\n",
    "\n",
    "# Concatenate the groups back into a single numpy array\n",
    "hfrl_paths_normalized_3d = np.concatenate(grouped.values, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "tensor_data = torch.tensor(hfrl_paths_normalized_3d, dtype=torch.float32)\n",
    "dataset = TensorDataset(tensor_data)\n",
    "data_loader = DataLoader(dataset, batch_size=33, shuffle=True)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5000  # You can adjust the number of epochs\n",
    "noise_dim = 100\n",
    "losses_ph = [] \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for real_data_tensor, in data_loader:\n",
    "        real_data_tensor = real_data_tensor.to(device)\n",
    "        \n",
    "        # Train Discriminator\n",
    "        # Generate fake data\n",
    "        noise = generate_noise(len(real_data_tensor), noise_dim)\n",
    "       # Random noise\n",
    "        fake_data = generator(noise)\n",
    "\n",
    "        # Get discriminator results for real and fake data\n",
    "        D_real = discriminator(real_data_tensor).view(-1)\n",
    "        D_fake = discriminator(fake_data.detach()).view(-1)\n",
    "\n",
    "        # Calculate loss on real and fake data\n",
    "        loss_D_real = criterion(D_real, torch.ones_like(D_real))\n",
    "        loss_D_fake = criterion(D_fake, torch.zeros_like(D_fake))\n",
    "        loss_D = (loss_D_real + loss_D_fake) / 2\n",
    "\n",
    "        # Update discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "         \n",
    "        # Update Value Network\n",
    "        feedback = collect_human_feedback(fake_data)\n",
    "        optimizer_value.zero_grad()\n",
    "        mse_loss = nn.MSELoss()\n",
    "        if isinstance(fake_data, list):\n",
    "            fake_data = torch.tensor(fake_data, dtype=torch.float).to(device)  # Convert list to tensor\n",
    "        predicted_feedback = value_network(fake_data)\n",
    "        feedback = feedback.view(predicted_feedback.shape)\n",
    "        value_loss = mse_loss(feedback, predicted_feedback)\n",
    "        value_loss.backward(retain_graph=True)\n",
    "        optimizer_value.step()\n",
    "        \n",
    "\n",
    "        # Train Generator\n",
    "        # Get discriminator results for fake data\n",
    "        output = discriminator(fake_data).view(-1)\n",
    "        \n",
    "        # Calculate loss for generator \n",
    "        phy_factor =best_params['phy_factor_param']\n",
    "        val_factor = 1\n",
    "        \n",
    "        loss_G = criterion(output, torch.ones_like(output)) - val_factor * value_loss.detach()  + phy_factor * physics_loss(fake_data)\n",
    "\n",
    "        # Update generator\n",
    "        optimizer_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "    # Optionally print the training progress\n",
    "    losses_ph.append({\"epoch\": epoch, \"D Loss\": loss_D.item(), \"G Loss\": loss_G.item() , \"Value Loss\": value_loss.item()})\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] Loss discriminator: {loss_D.item():.4f}, Loss generator: {loss_G.item():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5912b18-6546-4dbe-a45b-52e88230877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the data\n",
    "\n",
    "#Epoch: 41, Batch: 34, D Loss: 0.7058187127113342, G Loss: 0.6761125326156616, Value Loss: 9.605087280273438\n",
    "\n",
    "epochs_ls = [loss['epoch'] for loss in losses_ph]\n",
    "d_losses = [loss['D Loss'] for loss in losses_ph]\n",
    "print(sum(d_losses)/5000,\"d_losses\")\n",
    "\n",
    "g_losses = [loss['G Loss'] for loss in losses_ph]\n",
    "print(sum(g_losses)/5000,\"g_losses\")\n",
    "value_losses =  [loss['Value Loss'] for loss in losses_ph]\n",
    "print(np.mean(value_losses), \"value_losses\")\n",
    "d_losses_real = []\n",
    "d_losses_fake = []\n",
    "\n",
    "\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "#d_loss_real\n",
    "plt.plot(epochs_ls, d_losses, label='Discriminator Loss')\n",
    "\n",
    "plt.plot(epochs_ls, g_losses, label='Generator Loss')\n",
    "plt.plot(epochs_ls, value_losses, label='Reward Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Losses Over Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('Training Losses Over Epochs tcn.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dd5b60-692f-4ddb-ac1d-7cb858c8ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples\n",
    "noise_dim = 1000  # This should match the dimension used during training\n",
    "sample_count = 50000\n",
    "\n",
    "# Generate samples using a for loop\n",
    "samples_syth = []\n",
    "for i in range(sample_count):\n",
    "    sample = generate_samples(generator, 1, noise_dim)\n",
    "    samples_syth.append(sample)\n",
    "    \n",
    "samples_syth = torch.cat(samples_syth, dim=0)\n",
    "\n",
    "# Convert to NumPy array (if you need to save it as a .npy file)\n",
    "samples_syth = samples_syth.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e87a50-f861-4e58-aab3-ffd69e13a1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_syth_ph2 = denormalize_data(samples_syth, scaler_ph2,features)\n",
    "samples_syth_ph2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a846994a-0d28-4e47-bbf8-9e45102eb379",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract normalized time and energy into separate variables\n",
    "denormalize_generated_data = denormalize_data(concatenated_array, scaler, features)\n",
    "denormalize_generated_data.to_csv(\"denormalize_generated_data_ph2.csv\")\n",
    "time_denorm = samples_syth_ph2['Time']  # Assuming time is the second last column\n",
    "energy_denorm = samples_syth_ph2['Energy_Consumped']  # Assuming energy is the last column\n",
    "\n",
    "# Ensure the series length is a multiple of 5\n",
    "n = 5\n",
    "length = len(time_denorm)\n",
    "trimmed_length = length - (length % n)\n",
    "# Trim the series if necessary\n",
    "trimmed_series = time_denorm[:trimmed_length]\n",
    "# Reshape to groups of 5\n",
    "reshaped_array = trimmed_series.to_numpy().reshape(-1, n)\n",
    "# Sum each group of 5\n",
    "time_denorm_sums = reshaped_array.sum(axis=1)\n",
    "trimmed_series = energy_denorm[:trimmed_length]\n",
    "# Reshape to groups of 5\n",
    "reshaped_array = energy_denorm.to_numpy().reshape(-1, n)\n",
    "# Sum each group of 5\n",
    "energy_denorm_sums = reshaped_array.sum(axis=1)\n",
    "\n",
    "# Plotting\n",
    "plt.scatter(time_denorm_sums, energy_denorm_sums, color='blue')\n",
    "\n",
    "# Set title and labels\n",
    "plt.title('Synthetic Paths - Distribution of Cycle Time and Energy')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Energy')\n",
    "\n",
    "# Save and show the plot\n",
    "plt.savefig('denormalize-Synthetic Data.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3d0d7d-0203-4447-a4ad-a70e5bef49d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample data waed\n",
    "time = time_denorm_sums\n",
    "energy = energy_denorm_sums\n",
    "\n",
    "# Function to determine the Pareto front for minimizing both dimensions\n",
    "def pareto_frontier_minimize_both(Xs, Ys):\n",
    "    sorted_points = sorted([[Xs[i], Ys[i]] for i in range(len(Xs))], key=lambda point: (point[0], point[1]))\n",
    "    pareto_front = [sorted_points[0]]\n",
    "    for current in sorted_points[1:]:\n",
    "        if current[1] < pareto_front[-1][1]:\n",
    "            pareto_front.append(current)\n",
    "    return [pair[0] for pair in pareto_front], [pair[1] for pair in pareto_front]\n",
    "\n",
    "# Compute Pareto front\n",
    "pareto_X, pareto_Y = pareto_frontier_minimize_both(time, energy)\n",
    "\n",
    "# Plotting the points and Pareto front\n",
    "plt.scatter(time, energy, color='blue', label='Sythetic Paths')  \n",
    "plt.scatter(time_real, energy_real, color='green', label='Real Paths')\n",
    "plt.plot(pareto_X, pareto_Y, color='red', linewidth=2.0, label='Pareto Front')  # Pareto front\n",
    "\n",
    "plt.title('Synthetic & Real Paths - Distribution of Cycle Time and Energy')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Energy')\n",
    "plt.legend()\n",
    "plt.savefig('Synthetic & Real Paths- Pareto Visulization tgan.pdf')\n",
    "plt.show()\n",
    "\n",
    "# Identifying the a-bsolute optimal point (minimum energy and time)\n",
    "min_energy = min(pareto_Y)\n",
    "optimal_points = [(x, y) for x, y in zip(pareto_X, pareto_Y) if y == min_energy]\n",
    "print(\"Optimal Points (Min Energy and then Min  Time):\", optimal_points)\n",
    "print(pareto_X, pareto_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c12d3df-d332-4bd5-b56c-f96651242dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = time_denorm_sums\n",
    "energy =energy_denorm_sums\n",
    "\n",
    "\n",
    "\n",
    "# Function to identify Pareto optimal points\n",
    "def identify_pareto(scores):\n",
    "    # Initialize a boolean array to identify Pareto points\n",
    "    is_pareto = np.ones(scores.shape[0], dtype=bool)\n",
    "    for i in range(scores.shape[0]):\n",
    "        for j in range(scores.shape[0]):\n",
    "            if all(scores[j] <= scores[i]) and any(scores[j] < scores[i]):\n",
    "                is_pareto[i] = False\n",
    "                break\n",
    "    return is_pareto\n",
    "\n",
    "# Identify Pareto front\n",
    "pareto_points = identify_pareto(np.c_[time, energy])\n",
    "pareto_time = time[pareto_points]\n",
    "pareto_energy = energy[pareto_points]\n",
    "print(pareto_time, pareto_energy)\n",
    "# Ensure there are Pareto points before proceeding\n",
    "\n",
    "if pareto_time.size > 0 and pareto_energy.size > 0:\n",
    "    # Select the best point based on the shortest Euclidean distance from the origin\n",
    "    distances = np.sqrt(pareto_time**2 + pareto_energy**2)\n",
    "    best_index = np.argmin(distances)\n",
    "    best_time = pareto_time[best_index]\n",
    "    best_energy = pareto_energy[best_index]\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(time, energy, color='gray', label='Sythetic Paths')\n",
    "    plt.scatter(time_real, energy_real, color='green', label='Real Paths')\n",
    "\n",
    "    plt.scatter(pareto_time, pareto_energy, color='blue', label='Pareto Front')\n",
    "    plt.scatter(best_time, best_energy, color='red', label='Best Point')\n",
    "    plt.plot([0, best_time], [best_energy, best_energy], 'k--', lw=1)  # Horizontal line to Best Point\n",
    "    plt.plot([best_time, best_time], [0, best_energy], 'k--', lw=1)  # Vertical line to Best Point\n",
    "    plt.text(best_time, best_energy, ' Best Point', verticalalignment='bottom')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Energy')\n",
    "    plt.title('Pareto Front with Best Selected Point')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('Synthetic & Real Paths- Pareto Visulization tgan best point.pdf')\n",
    "\n",
    "else:\n",
    "    print(\"No Pareto optimal points were identified.\")\n",
    "print(best_time,best_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee8694f-db7f-4e10-8508-d325e4f60dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b93a325-48b3-45dd-9472-ddc1a881562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "from torchinfo import summary\n",
    "\n",
    "model = SimpleCNN()\n",
    "summary(model, input_size=(1, 1, 28, 28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6926449-9094-4acc-8ff9-774bc47dc5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchinfo\n",
    "!pip install torchsummary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed517be-c685-4e15-9852-0d278a7db568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "# Improvement calculation\n",
    "def improvement_ratio(real, generated):\n",
    "    time_improvement = (real[0] - generated[0]) / real[0] if real[0] != 0 else 0\n",
    "    energy_improvement = (real[1] - generated[1]) / real[1] if real[1] != 0 else 0\n",
    "    return time_improvement, energy_improvement\n",
    "\n",
    "# Example usage:\n",
    "real_point = (3.18, 58.5091)\n",
    "generated_point = (best_time, best_energy)\n",
    "\n",
    "\n",
    "# Get improvements\n",
    "time_improvement, energy_improvement = improvement_ratio(real_point, generated_point)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Time Improvement Ratio: {time_improvement:.2%}\")\n",
    "print(f\"Energy Improvement Ratio: {energy_improvement:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbb56f3-110f-4b82-b6e6-0c0e7ab17ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd423a13-a2e0-438c-b95a-2b5a9b041ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
